# OpenGalea Documentation

## By Team Syncer
**Contributors:** Alif Jakir, Tsing Liu, Soo Bin Park, Yechan Ian Seo, Syed Hussain Ather

---

### Narrative

#### Prolegomena
The evolution of how Homo sapiens engage in play and interact with digital information has undergone a seismic shift over the past century, reshaping what is possible, perceivable, and imaginable on Earth. From the first Graphical User Interface introduced with the Xerox Alto in 1973 at Xerox PARC to hyper-realistic ray-traced virtual worlds accessible through devices like the Varjo XR-4, this progress demonstrates the increasing programmability of information experiences. Higher bandwidth interactions between users and digital environments are now achievable.

The introduction of immersive neural interfaces through open-source development has immense potential, enabling wisdom-of-the-crowd collaboration to shape the future of interaction technology. Despite the Quest 3’s landmark release on October 10th, 2023, delivering affordable, high-quality, low-latency, full-color video passthrough in a mobile XR device, integration into open-source brain-computer interfaces (BCIs) remains complex. OpenGalea bridges this gap, offering an accessible and open-source solution for creating valuable datasets and interactive closed-loop visual and auditory experiences that are entirely brain-controlled.

---

### Description
**What is OpenGalea?**
OpenGalea was developed to address the lack of open-source solutions in the mixed-reality neurotechnology space. By leveraging advancements in the Quest 3’s software stack, we showcase novel use cases of co-located mixed reality—a concept that enables shared virtual environments overlaid on the same physical space occupied by multiple users. This fosters unparalleled immersion, integrating virtual information seamlessly into the real world.

Our project was created as part of the hardware track at MIT Reality Hack—a yearly hackathon that inspires intense collaboration on mixed reality, AI, hardware, software, and game development. Learn more at [MIT Reality Hack](https://www.mitrealityhack.com/).

---

### Use Cases
1. **Gaming:** Revolutionizing game mechanics by enabling players to control virtual elements directly with their brainwaves.
2. **Therapeutic Applications:** Creating meditative and calming experiences through neuroadaptive environments.
3. **Collaborative Training:** Enhancing team-based learning and coordination through shared virtual interactions.
4. **Accessibility:** Providing a cost-effective alternative to high-priced neurotech solutions like Galea.

---

### Cost Comparison
- **Galea**: $30,000
- **OpenGalea**:
  - Quest 3: $450
  - 8-channel Cyton: $1,000
  - Unassembled Ultracortex print: $400
  - Small weights and bands: $20
  - Printing costs: $30
- **Total**: **$1,900**
**OpenGalea is 15.8x cheaper than Galea.**

[Add Bill of Materials (BOM) link here]

---

### Technical Features
#### Tracks:
1. **Two-Axis Interaction:**
   - Object movement along the x-axis when a user is in an active state.
   - Relaxation (e.g., closed eyes) halts object movement.
   - Two users introduce two axes for collaborative interaction.

#### Hardware Development:
- Weight adjustments and balance: 2 hours.
- 3D printing (front + back): 1 hour.
- Lock mechanism using Velcro straps: 1 hour.
- High-quality rendering design (Vizcom): 2 hours.

#### Mixed Reality Experience:
- Virtual environments featuring interactive, co-located shared objects.
- Touch-responsive, brainwave-driven transformations (e.g., Alpha wave manipulation).
- Cross-device communication: Each Quest headset receives EEG streams from separate laptops using OpenBCI GUI and UDP protocols.

#### Data Streams:
- **Alpha waves (0-100):** Brainwave data translated into real-time Unity interactions.
- Multi-stream architecture for synchronized co-location effects.

---

### Documentation & Resources
1. **Code Repository:**
   - Comprehensive README.md with installation and setup instructions.
   - Pages for individual components, including:
     - Hardware design and assembly.
     - 3D printing methods.
     - Software architecture and implementation.
     - Mixed Reality onboarding for single and multiplayer modes.
     - Machine learning and neural data processing.
2. **Philosophy:**
   - Open-source neuroadaptive systems democratizing access to advanced mixed-reality technologies.
3. **Troubleshooting:**
   - Common issues and solutions for hardware and software setup.

---

### Video Submission Script
#### Opening (0:00 - 0:15)
- **Visual:** Title card with "OpenGalea" logo, team name (Team Syncer), and "MIT Reality Hack 2025."
- **Voiceover:** "OpenGalea combines brainwave data with mixed reality to create dynamic, mind-driven interactions. Powered by EEG technology, it’s a new frontier in neuroadaptive VR and AR."

#### Hardware Showcase (0:15 - 0:30)
- **Visual:** Close-up shots of OpenBCI headset, Ultracortex components, and Quest 3 integration.
- **Voiceover:** "The Ultracortex headset captures brainwave activity, translating it into real-time animations within a virtual world."

#### Core Functionality (0:30 - 1:00)
- **Visual:** Split-screen of EEG alpha data stream and VR/AR interactions.
- **Voiceover:** "As alpha waves increase, the virtual garden transforms into vibrant, interactive experiences. Multiplayer synchronization unlocks cooperative animations."

#### Impact Statement (1:00 - 1:30)
- **Visual:** Use case highlights: gaming, therapy, meditation, and training.
- **Voiceover:** "OpenGalea bridges the gap between mind and machine, enabling groundbreaking applications in immersive experiences."

#### Closing (1:30 - 2:00)
- **Visual:** Animated transformation of a serene virtual garden.
- **Voiceover:** "OpenGalea: Pioneering a neuroadaptive future. Ready to experience the future of mixed reality? Visit our GitHub and learn more today!"
- **Overlay:** GitHub link and team credits.

---

### Next Steps
- Submit GitHub repo, Devpost page, and updated team profile on RealityHack.world.
- Deliver two videos:
  1. 30-second sizzle reel.
  2. 2-minute documentation video.

---

### Pop Culture Inspirations
- **Pacific Rim:** Cooperative control akin to piloting a Jaeger together.
- **Cerebro (X-Men):** Harnessing brainwaves for augmented perception.
- **Neon Genesis Evangelion:** Using brain-like components for advanced simulations and synchronizations.

---

## Team Syncer
OpenGalea | MIT Reality Hack 2025

